{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. Basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the toolbox is a package tree.\n",
    "\n",
    "You need to import the \\_\\_init\\_\\_.py file at the root of each package add the toolbox toplevel to your path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import __init__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Database\n",
    "\n",
    "The voc database is instanciated with a given voc stored in a file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cpLib.conceptDB as db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ther are 2 saved database format.\n",
    "\n",
    "* Text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d = db.DB('../data/voc/txt/googleNews_mini.txt', verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which is quite slow to load for large voc. Due to performance issues, we need to use numpy format for large voc.\n",
    "\n",
    "* Npy matrix and an association dictionary\n",
    "\n",
    "The voc is then splited in 2 files: one containing the matrix (in npy format), the other for words association (a dict in json format)\n",
    "\n",
    "_NB: for both loading approach, you can verbose or not, it is usefull to deal with files created by std redirection_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 loaded from googleNews_mini\n",
      "mem usage 17.6KiB\n",
      "loaded time 0.017294883728 s\n"
     ]
    }
   ],
   "source": [
    "d = db.DB('../data/voc/npy/googleNews_mini.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract concept\n",
    "\n",
    "We will refer as __concept__ for a word and his associated vector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Load an existing concept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "king <type 'numpy.ndarray'> 300\n"
     ]
    }
   ],
   "source": [
    "v1 = d.get('king')\n",
    "print v1, type(v1.vect), len(v1.vect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Load a missing concept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "v2 = d.get('toto')\n",
    "print v2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Check if a concept is in the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print d.has('king')\n",
    "print d.has('toto')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Extract a random sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "woman\n"
     ]
    }
   ],
   "source": [
    "conceptList = d.getSample(5)\n",
    "print len(conceptList)\n",
    "print conceptList[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find concept"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A common operation is to find the closest word for a given concept.\n",
    "\n",
    "You can do this according to several metrics\n",
    "\n",
    "* Cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.6510957479476929, 'queen'), (0.22942674160003662, 'man'), (0.14300569891929626, 'tiger'), (0.1284797489643097, 'woman'), (0.12812507152557373, 'dog'), (0.1216159388422966, 'cat'), (0.11390406638383865, 'feline'), (0.07803817838430405, 'bird'), (0.06225873529911041, 'truck'), (0.06189548596739769, 'car')]\n"
     ]
    }
   ],
   "source": [
    "king = d.get('king')\n",
    "print d.find_cosSim(king)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Euclidean distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(2.479691982269287, 'queen'), (2.9016165733337402, '</s>'), (3.2687888145446777, 'man'), (3.673551321029663, 'woman'), (3.8052330017089844, 'car'), (3.8849875926971436, 'dog'), (3.9377858638763428, 'cat'), (3.98100209236145, 'truck'), (4.0085577964782715, 'feline'), (4.019833087921143, 'vehicle')]\n"
     ]
    }
   ],
   "source": [
    "print d.find_euclDist(king)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Manhattan distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(34.99564743041992, 'queen'), (40.426326751708984, '</s>'), (44.956417083740234, 'man'), (49.59609603881836, 'woman'), (52.44883728027344, 'car'), (54.61458206176758, 'dog'), (54.72962188720703, 'feline'), (54.86988067626953, 'cat'), (54.87595748901367, 'truck'), (55.824737548828125, 'vehicle')]\n"
     ]
    }
   ],
   "source": [
    "print d.find_manaDist(king)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can apply several operations between concepts to build new ones.\n",
    "\n",
    "Created concept names are in reverse polish notation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cpLib.concept as cp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Add and substract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__-____+__king__man__queen  ~  woman\n",
      "__-____+____n__king____n__man____n__queen  ~  woman\n"
     ]
    }
   ],
   "source": [
    "v1 = cp.add(d.get('king'), d.get('man'))\n",
    "v1 = cp.sub(v1, d.get('queen'))\n",
    "\n",
    "v2 = cp.addSub([d.get('king'), d.get('man')], [d.get('queen')], normalized=True)\n",
    "\n",
    "print v1, ' ~ ', d.find_cosSim(v1)[0][1]\n",
    "print v2, ' ~ ', d.find_cosSim(v2)[0][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Normalized concept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__n__king\n"
     ]
    }
   ],
   "source": [
    "k = d.get('king')\n",
    "print k.normalized()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Polar coordinate\n",
    "\n",
    "Transform the carthesian coordinate into hyperspherical ones.\n",
    "\n",
    "First value is the norm, the other values are angles in rad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__p__king\n",
      "norm = 2.90226\n",
      "1st angle = 1.52738\n"
     ]
    }
   ],
   "source": [
    "k = d.get('king')\n",
    "print k.polarized()\n",
    "print 'norm =', k.polarized().vect[0]\n",
    "print '1st angle =', k.polarized().vect[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Angular coordinates\n",
    "\n",
    "Polar transformation without the norm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__a__king\n",
      "vector dimension = 299\n",
      "1st angle = 1.52738\n"
     ]
    }
   ],
   "source": [
    "k = d.get('king')\n",
    "print k.angularized()\n",
    "print 'vector dimension =', len(k.angularized().vect)\n",
    "print '1st angle =', k.angularized().vect[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concept feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since this toolbox is designed in a first place for machine learning activies, we provide some feature extraction functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import mlLib.conceptFeature as cpf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Identity vector\n",
    "\n",
    "Identity vector is the raw vector in the vector space in carthesian coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n"
     ]
    }
   ],
   "source": [
    "k = d.get('king')\n",
    "print len(cpf.identity(k))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Polar vector\n",
    "\n",
    "We can also transform this carthesian coordinates into hyperspherical ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n"
     ]
    }
   ],
   "source": [
    "k = d.get('king')\n",
    "print len(cpf.polar(k))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Angular vector\n",
    "\n",
    "And remove the norm to keep only the angle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "299\n"
     ]
    }
   ],
   "source": [
    "k = d.get('king')\n",
    "print len(cpf.angular(k))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__In practice, we discovered the semantic meaning of the norm tends to be the 'specialisation' of the concept. and the angle the field of application.__\n",
    "\n",
    "__Thus:__\n",
    "* Angular and Polar features will we more adapted to classify domains\n",
    "* Carthesian usefull when we need to access the 'deepness' of the concept\n",
    "\n",
    "You can check _dataExploration_ folder notebook for more details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concept pair feature\n",
    "\n",
    "A common usecase for supervised learning would be to detect the relation between 2 concepts.\n",
    "\n",
    "We also provide so comparison features for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import mlLib.conceptPairFeature as cppf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To keep a trace of the feature transformation used and keep a high level manipulation, we'll adopt the following operation for a conceptPair:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(king, 'relation', queen)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conceptPair = (d.get('king'), 'relation', d.get('queen'))\n",
    "conceptPair"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Classic feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are simple operations: substraction and concatenation of 2 concept features presented in the previous part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature dimension depending of the used function\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carthesian</th>\n",
       "      <th>polar</th>\n",
       "      <th>angular</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>substraction</th>\n",
       "      <td>300</td>\n",
       "      <td>300</td>\n",
       "      <td>299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>concatenation</th>\n",
       "      <td>600</td>\n",
       "      <td>600</td>\n",
       "      <td>598</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               carthesian  polar  angular\n",
       "substraction          300    300      299\n",
       "concatenation         600    600      598"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conceptPair = (d.get('king'), 'relation', d.get('queen'))\n",
    "\n",
    "featureDimDf = pd.DataFrame(index=['substraction', 'concatenation'])\n",
    "featureDimDf['carthesian'] = [len(feature(conceptPair)) for feature in [cppf.subCarth, cppf.concatCarth]]\n",
    "featureDimDf['polar'] = [len(feature(conceptPair)) for feature in [cppf.subPolar, cppf.concatPolar]]\n",
    "featureDimDf['angular'] = [len(feature(conceptPair)) for feature in [cppf.subAngular, cppf.concatAngular]]\n",
    "\n",
    "print 'feature dimension depending of the used function'\n",
    "featureDimDf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Projection features\n",
    "\n",
    "We also introduced another type of concept relation.\n",
    "\n",
    "Based on the idea it would be usefull to __compare similarity between 2 concepts for each dimension__, we introduced some 'projection metrics' features.\n",
    "\n",
    "* Advantage: a feature to compare 2 concepts similarity according to each dimension.\n",
    "* Drawback: __not commutative__ so not usefull for 'ordered' pairs\n",
    "\n",
    "So far, we provide the projection features for the following metrics:\n",
    "* Cosine similarity\n",
    "* Euclidean distance\n",
    "* Manhattan distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature dimension: 300\n"
     ]
    }
   ],
   "source": [
    "cppf.pCosSim(conceptPair)\n",
    "cppf.pEuclDist(conceptPair)\n",
    "print 'feature dimension:', len(cppf.pManaDist(conceptPair))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature dimension: 300\n"
     ]
    }
   ],
   "source": [
    "cppf.pdCosSim(conceptPair)\n",
    "cppf.pdEuclDist(conceptPair)\n",
    "print 'feature dimension:', len(cppf.pdManaDist(conceptPair))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Projection similarity\n",
    "The idea is to use a metric on the projected vectors for each dimension of the vector\n",
    "We could introduce it as:\n",
    "\n",
    "__\"Beside this dimension $i$, how A and B are similar ?\"__\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___Formal approach_:__\n",
    "\n",
    "* $E$: the word vector space, $E \\in \\mathbb{R}^{n}$\n",
    "* $a, b \\in E$\n",
    "* $m$: a metric $m \\in E \\mapsto \\mathbb{R}$\n",
    "\n",
    "Given a projection operator on dimension $i$:\n",
    "\n",
    "$P_{i}(a) = a_{i \\neq j}$\n",
    "\n",
    "We define the projection similarity for metric $m$:\n",
    "\n",
    "$P_{m, i}(a, b) = m(P_{i}(a), P_{i}(b))$\n",
    "\n",
    "We apply it to each dimension and get the feature vector:\n",
    "\n",
    "$\\vec{P_{m}}(a, b) = \\sum \\limits_{i=1}^n P_{m, i}(a, b) \\vec{e_{i}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Projection dissimilarity\n",
    "\n",
    "We introduced the projection dissimilarity as the difference between a defined metric and the projected ones of each dimensions.\n",
    "\n",
    "We could translate it as:\n",
    "\n",
    "__\"_How important is this dimension $i$ important to mesure the similarity between A and B ?_\"__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___Formal approach_:__\n",
    "\n",
    "We use the same notation as in previous section to define the projection dissimilarity:\n",
    "\n",
    "$Pd_{m, i}(a, b) = m(a, b) - m(P_{i}(a), Pd_{i}(b))$\n",
    "\n",
    "Same, same but different =), we also apply it to each dimension to get the feature vector:\n",
    "\n",
    "$\\vec{Pd_{m}}(a, b) = \\sum \\limits_{i=1}^n Pd_{m, i}(a, b) \\vec{e_{i}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___________________________________\n",
    "\n",
    "# II. Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build learning sample\n",
    "\n",
    "For supervised learning task, this toolbox propose a high level solution:\n",
    "\n",
    "Provide the dataset and the extraction feature function to an overlay classifier.\n",
    "\n",
    "* The dataset is either a list of concepts or a list of concept pair we describe above.\n",
    "* The overlay classifier is built with a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[king, queen, cat, bird]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cpLib.conceptExtraction as cpe\n",
    "\n",
    "conceptStrList = ['king', 'queen', 'cat', 'bird', 'king bird']\n",
    "\n",
    "cpe.buildConceptList(d, conceptStrList, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last boolean argument allow to try to compose concept for unknown words based on existing vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[king, queen, cat, bird, __m__king__bird]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cpe.buildConceptList(d, conceptStrList, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concept pair\n",
    "\n",
    "Almost the same function are exposed for for building concept pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(king, 'relation', queen)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conceptPairStrList = [('king', 'relation', 'queen'),\n",
    "                      ('man', 'relation', 'woman'),\n",
    "                      ('bird', 'relation', 'cat')]\n",
    "\n",
    "\n",
    "conceptPairList = cpe.buildConceptPairList(d, conceptPairStrList, True)\n",
    "conceptPairList[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To build a negative sample in concept pair, you can shuffle an existing pair list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(cat, 'relation', king), (queen, 'relation', man), (woman, 'relation', bird)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cpe.shuffledConceptPairList(conceptPairList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use a classifier\n",
    "\n",
    "We use _dill_ to serialise trained model, here is a few scripts to use trained models.\n",
    "\n",
    "__you need to make sure the vocabulary file you are using to predict is the same that has been used to fit the classifier.__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Predict\n",
    "\n",
    "Theses scripts use a __trained classifier__ to predict the class of every element of a dataset.\n",
    "\n",
    "#### Single Concept\n",
    "\n",
    "This script predict the classes of __single concept__ dataset for a trained model, here is an example:\n",
    "```\n",
    "python toolbox/script/predictConceptClass.py data/voc/npy/wikiEn-skipgram.npy data/learnedModel/domain/animal-plant-vehicle-other_strict_RandomForestClassifier_angular_noPost.dill data/domain/luu_animal.txt\n",
    "```\n",
    "\n",
    "#### ConceptPair\n",
    "\n",
    "This script predict the classes of __concept pair__ dataset for a trained model, here is an example:\n",
    "```\n",
    "python toolbox/script/predictConceptPairClass.py data/voc/npy/wikiEn-skipgram.npy data/learnedModel/anto/simple__RandomForestClassifier_pCosSim_noPost.dill data/wordPair/wordnetAnto.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Find most likely pair\n",
    "\n",
    "This script use a __trained concept pair classfier__ to __find the most likely match__ in all the vocabulary __for a given single concept__, here is an example:\n",
    "```\n",
    "python toolbox/script/findMostLikelyPair.py data/voc/npy/wikiEn-skipgram.npy data/learnedModel/taxo/animal__RandomForestClassifier_subAngular_postNormalize.dill cat isParent --domain data/domain/luu_animal.txt\n",
    "```\n",
    "\n",
    "_NB: You can restrict the searching sample with the --domain argument. this avoid to go throught the whole vocabulary_\n",
    "\n",
    "\n",
    "_NB 2: RandomForest models are not adapted for this application_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c. Evaluate a classifier\n",
    "\n",
    "Theses scripts retrain and evaluate a classifier model, train it (__without kfold__) and print the report.\n",
    "\n",
    "#### Single Concept\n",
    "\n",
    "This script evaluate a models for a __single concept dataset__ input, here is an example:\n",
    "```\n",
    "python toolbox/script/detailConceptClfError.py data/voc/npy/wikiEn-skipgram.npy data/learnedModel/domain/animal-other__RandomForestClassifier_angular_postNormalize.dill data/domain/luu_animal.txt animal data/domain/all_1400.txt other\n",
    "```\n",
    "\n",
    "#### ConceptPair\n",
    "\n",
    "This script evaluate a models for a __concept pair dataset__ input, here is an example:\n",
    "```\n",
    "python toolbox/script/detailConceptPairClfError.py data/voc/npy/wikiEn-skipgram.npy data/learnedModel/anto/bidi__RandomForestClassifier_pCosSim_postNormalize.dill data/wordPair/wordnetAnto.txt anto data/wordPair/wordnetAnto_fake.txt notAnto\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___________________________________\n",
    "\n",
    "\n",
    "# III. Build database\n",
    "\n",
    "You may want to train your own word2vec vectorial space.\n",
    "\n",
    "This toolbox comes with some existing project to train a vocabulary and can convert it to a python friendly format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From a binary file\n",
    "\n",
    "Here is the workflow to build a database from a bin file.\n",
    "\n",
    "* If you don't have a .bin vector file yet, use Word2vec to train your corpus to a .bin vect file:\n",
    "\n",
    "```\n",
    "thirdparty/word2vec/bin/word2vec -train pathToCorpus.txt -output data/voc/bin/text8.bin -size 200 -window 5 -sample 1e-4 -negative 5 -hs 0 -binary 0\n",
    "```\n",
    "\n",
    "You choose here all the parameters for training your vector space\n",
    "\n",
    "* Use convertvec to convert .bin to .txt vector file:\n",
    "```\n",
    "thirdparty/convertvec bin2txt data/voc/bin/text8.bin data/voc/txt/text8.txt\n",
    "```\n",
    "\n",
    "* Use the script ```convertTxtDbToNpy.py``` to create and save the npy matrix and the association dictionary:\n",
    "```\n",
    "python toolbox/bin/convertTxtDbToNpy.py data/voc/txt/text8.txt data/voc/npy/text8.npy\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert a database to polar / angular coordinates\n",
    "\n",
    "Since we use transformation from cathersian to polar / angular coordinates, we created a script to convert a database in this space.\n",
    "\n",
    "\n",
    "\n",
    "* Convert to polar coordinates\n",
    "```\n",
    "python toolbox/bin/convertCarthDbToPolar.py data/voc/npy/text8.npy data/voc/npy\n",
    "```\n",
    "\n",
    "* Convert to angular coordinates\n",
    "```\n",
    "python toolbox/bin/convertCarthDbToPolar.py data/voc/npy/text8.npy data/voc/npy --angular\n",
    "```\n",
    "\n",
    "_NB: you can convert from a .txt voc file but for perfomance reason, we strongly advise to use .npy format._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___________________________________\n",
    "\n",
    "\n",
    "# IV. Run the experiment\n",
    "\n",
    "You may want to reproduce the experiences. It is detailled in each dedicated notebook but all script are in:\n",
    "```\n",
    "toolbox/experiement\n",
    "```\n",
    "\n",
    "To reproduce the log extraction you will need to redirect the output to a log file like this:\n",
    "```\n",
    "python toolbox/experiment/trainAll_antoClf.py > data/learnedModel/anto/log.txt\n",
    "```\n",
    "\n",
    "Split it:\n",
    "```\n",
    "python toolbox/bin/splitLogFile.py data/learnedModel/anto/log.txt\n",
    "```\n",
    "\n",
    "And finally use:\n",
    "```\n",
    "bash toolbox/bin/summarizeAllSkReport.sh\n",
    "```\n",
    "To extract proper summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___________________________________\n",
    "\n",
    "\n",
    "# HAVE FUN !!\n",
    "and don't be evil:)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
